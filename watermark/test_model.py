import torch
import torch.serialization
import os
import sys

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# ì •í™•í•œ ëª¨ë“ˆ ê²½ë¡œë¡œ importí•´ì•¼ í•¨
import watermark.configs as configs
from watermark.models.encoder import Encoder
from watermark.models.decoder import Decoder

# âœ… torchì—ê²Œ configs.ModelConfigë¥¼ ì•ˆì „í•˜ê²Œ í—ˆìš©
torch.serialization.add_safe_globals([configs.ModelConfig])

# config ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
config = configs.ModelConfig()

# ëª¨ë¸ ì •ì˜
encoder = Encoder(config)
decoder = Decoder(config)

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
# ckpt_path = "weights/paper.ckpt"
# ckpt = torch.load(ckpt_path, map_location="cpu", weights_only=False)  # ğŸ”¥ ì—¬ê¸°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•¨!

ckpt = torch.load("weights/paper.ckpt", map_location=torch.device("cpu"), weights_only=False)
print(ckpt["decoder_state_dict"].keys())
sd = ckpt["decoder_state_dict"]
sd = {k: v for k, v in sd.items() if not k.startswith("extractor.classifier")}


encoder.load_state_dict(ckpt["encoder_state_dict"])
decoder.load_state_dict(sd, strict=False)

encoder.eval()
decoder.eval()

# í…ŒìŠ¤íŠ¸ ì…ë ¥
dummy_img = torch.randn(1, 3, config.image_shape[0], config.image_shape[1])
dummy_wm = torch.randn(1, config.num_encoded_bits)

with torch.no_grad():
    encoded = encoder(dummy_img, dummy_wm)

    # ì´ë¯¸ flatten í–ˆë‹¤ë©´ ë‹¤ì‹œ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³µì›
    encoded = encoded.view(1, 3, 256, 256)  # or use config.image_shape

    decoded = decoder(encoded)

    print("Encoded image shape:", encoded.shape)
    print("Decoded watermark bits:", decoded)