from __future__ import annotations
import uuid, io
from pathlib import Path
from typing import Tuple, Optional, List
from gradio.themes import Soft

import cv2
import numpy as np
from PIL import Image

import gradio as gr

# ìš°ë¦¬ í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from watermark.configs import UPLOAD_DIR, OUTPUT_DIR
from watermark.embedder import embed_watermark, decode_watermark

# ---- Optional: CLIP (ì—†ìœ¼ë©´ Protect-onlyë¡œ í´ë°±) ----
_CLIP_OK = True
try:
    import torch
    import torch.nn.functional as F
    import torchvision.transforms as T
    import open_clip
except Exception:
    _CLIP_OK = False

ALLOWED_EXTS = {".png", ".jpg", ".jpeg"}

# ---------------------------
# Util
# ---------------------------
def _ensure_dirs():
    UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def _imread_rgb(path: str) -> np.ndarray:
    bgr = cv2.imread(path, cv2.IMREAD_COLOR)
    if bgr is None:
        raise FileNotFoundError(path)
    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)

def _imwrite_rgb(path: str, rgb: np.ndarray) -> None:
    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
    cv2.imwrite(path, bgr)

def _resize_like(a: np.ndarray, ref: np.ndarray) -> np.ndarray:
    if a.shape[:2] == ref.shape[:2]:
        return a
    return cv2.resize(a, (ref.shape[1], ref.shape[0]), interpolation=cv2.INTER_LANCZOS4)

def _psnr(a: np.ndarray, b: np.ndarray) -> float:
    a = a.astype(np.float32); b = b.astype(np.float32)
    mse = np.mean((a-b)**2)
    return float("inf") if mse < 1e-12 else 20.0*np.log10(255.0/np.sqrt(mse))

# ---------------------------
# Fast Disrupt (single image)
# ---------------------------
def _pil_to_tensor_01(img: Image.Image, size=224):
    tfm = T.Compose([T.Resize(size, interpolation=T.InterpolationMode.BICUBIC),
                     T.CenterCrop(size),
                     T.ToTensor()])
    return tfm(img)  # [0,1], 3x224x224

def _clip_norm(x: torch.Tensor):
    mean = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=x.device)[:,None,None]
    std  = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=x.device)[:,None,None]
    return (x - mean) / std

def disrupt_once(rgb_in: np.ndarray,
                 text_prompt: str = "a photo of an object",
                 steps: int = 3, eps: float = 8/255, alpha: float = 3/255
                 ) -> np.ndarray:
    """
    ê²½ëŸ‰ EOT-PGDë¡œ ì‹œê° í’ˆì§ˆ ìœ ì§€í•˜ë©° CLIP ì •ë ¬ì„ êµë€.
    - ì…ë ¥/ì¶œë ¥: RGB uint8 [H,W,3] (ê²°ê³¼ í•´ìƒë„ëŠ” ì…ë ¥ê³¼ ë™ì¼)
    """
    if not _CLIP_OK:
        # CLIPì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (Protect-only ë°ëª¨)
        return rgb_in.copy()

    device = torch.device("mps" if torch.backends.mps.is_available() else ("cuda" if torch.cuda.is_available() else "cpu"))
    model, _, _ = open_clip.create_model_and_transforms("ViT-B-32",
                        pretrained="laion2b_s34b_b79k", device=device)
    tokenizer = open_clip.get_tokenizer("ViT-B-32")

    # í…ìŠ¤íŠ¸ íŠ¹ì§• (ë‹¨ì¼ í”„ë¡¬í”„íŠ¸)
    with torch.inference_mode():
        tok = tokenizer([text_prompt]).to(device)
        tfeat = model.encode_text(tok)
        tfeat = tfeat / tfeat.norm(dim=-1, keepdim=True)

    # *** ì—¬ê¸°ê°€ í•µì‹¬: ì¶”ë¡ ëª¨ë“œ í…ì„œë¥¼ ê·¸ë˜í”„ ë°– "ì¼ë°˜ í…ì„œ"ë¡œ ë³€í™˜ ***
    tfeat = tfeat.detach().clone()  # inference í…ì„œ â†’ ì¼ë°˜ í…ì„œ
    # ì´ë¯¸ì§€ íŠ¹ì§• dtypeê³¼ ë§ì¶”ê¸°(half/float í˜¼ìš© ë°©ì§€)
    # ì•„ë˜ dtype ë§¤ì¹­ì€ img_feat ì‚°ì¶œ ì´í›„ì—ë„ í•œ ë²ˆ ë” ì•ˆì „í•˜ê²Œ ì ìš©í•©ë‹ˆë‹¤.

    # CLIP ì…ë ¥ ì¤€ë¹„
    pil = Image.fromarray(rgb_in)
    x0 = _pil_to_tensor_01(pil, size=224).to(device)  # [0,1]
    x = x0.clone().detach()
    delta = torch.zeros_like(x, requires_grad=True)

    for _ in range(max(1, steps)):
        # (EOT ë³€í˜•ì€ ê¸°ì¡´ê³¼ ë™ì¼)
        s = np.random.uniform(0.92, 1.00)
        size = int(224 * s)
        x_aug = F.interpolate((x + delta).unsqueeze(0), size=(size, size),
                              mode="bilinear", align_corners=False)
        x_aug = F.interpolate(x_aug, size=(224, 224), mode="bilinear", align_corners=False).squeeze(0).clamp(0, 1)

        # --- CLIP forward (gradient í•„ìš”) ---
        xn = _clip_norm(x_aug)
        # í˜¹ì‹œ ëª¨ë¥¼ ì „ì—­ ì¶”ë¡  ëª¨ë“œì— ëŒ€ë¹„
        with torch.enable_grad():
            img_feat = model.encode_image(xn.unsqueeze(0))
        img_feat = img_feat / img_feat.norm(dim=-1, keepdim=True)

        # *** dtype/ë””ë°”ì´ìŠ¤ ë§¤ì¹­ + inference í…ì„œ ê¸ˆì§€ ***
        if tfeat.dtype != img_feat.dtype:
            tfeat = tfeat.to(img_feat.dtype)
        if tfeat.device != img_feat.device:
            tfeat = tfeat.to(img_feat.device)

        # ìœ ì‚¬ë„(ë‹¨ì¼ í”„ë¡¬í”„íŠ¸): ì˜¬ë°”ë¥¸ ì •ë ¬ ìµœì†Œí™”
        sim = (img_feat @ tfeat.T).squeeze(0)[0]
        loss = sim
        loss.backward()

        # PGD step
        with torch.no_grad():
            delta += alpha * delta.grad.sign()
            delta.clamp_(-eps, eps)
            (x + delta).clamp_(0, 1)
        delta.grad.zero_()

    # 224â†’ì›ë³¸ í•´ìƒë„ ë³µì›(ê¸°ì¡´ê³¼ ë™ì¼)
    x_out = (x + delta).clamp(0, 1).detach().cpu()
    out_224 = (x_out.permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)
    out_full = cv2.resize(out_224, (rgb_in.shape[1], rgb_in.shape[0]), interpolation=cv2.INTER_LANCZOS4)
    return out_full

# ---------------------------
# Diagnostics (heatmap/FFT/overlay)
# ---------------------------
def make_diagnostics(orig_rgb: np.ndarray, pd_rgb: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, str]:
    pd_rgb = _resize_like(pd_rgb, orig_rgb)
    diff = (pd_rgb.astype(np.float32) - orig_rgb.astype(np.float32))

    # Heatmap (ì”ì°¨)
    mag = np.abs(diff).mean(axis=2)
    mag = mag / (mag.max() + 1e-8)
    heat = (mag*255).astype(np.uint8)
    heat = cv2.applyColorMap(heat, cv2.COLORMAP_INFERNO)
    heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)

    # FFT(ì›ë³¸/ê²°ê³¼ì˜ ìŠ¤í™íŠ¸ëŸ¼ ë¹„êµ) â€“ ê²°ê³¼ë§Œ ë³´ì—¬ì¤˜ë„ ì¶©ë¶„
    def fft_image(xrgb: np.ndarray):
        gray = cv2.cvtColor(xrgb, cv2.COLOR_RGB2GRAY).astype(np.float32)
        f = np.fft.fftshift(np.fft.fft2(gray))
        amp = np.log1p(np.abs(f))
        amp = (amp - amp.min())/(amp.max()-amp.min()+1e-8)
        return (amp*255).astype(np.uint8)

    fft_pd = cv2.applyColorMap(fft_image(pd_rgb), cv2.COLORMAP_INFERNO)
    fft_pd = cv2.cvtColor(fft_pd, cv2.COLOR_BGR2RGB)

    # Overlay (ì›ë³¸ ìœ„ì— ì”ì°¨ ê°•ì¡°)
    scale = 6.0  # ë³´ê¸°ìš© ê°€ì¤‘
    overlay = np.clip(orig_rgb.astype(np.float32) + scale*diff, 0, 255).astype(np.uint8)

    # í’ˆì§ˆ ìˆ˜ì¹˜
    psnr_val = _psnr(orig_rgb, pd_rgb)
    note = f"PSNR (orig vs PD): {psnr_val:.2f} dB"

    return heat, fft_pd, overlay, note

# ---------------------------
# One-shot pipeline
# ---------------------------
def run_one_shot(file, steps=3, eps=8/255, alpha=3/255):
    """
    ì—…ë¡œë“œ â†’ Protect(ì›Œí„°ë§ˆí¬) â†’ Disrupt â†’ ê²°ê³¼/UUID/ì‹œê°í™” ë°˜í™˜
    """
    if file is None:
        return None, None, [], "Please upload an image first.", ""

    _ensure_dirs()

    in_path = Path(file.name if hasattr(file, "name") else str(file))
    ext = in_path.suffix.lower()
    if ext not in ALLOWED_EXTS:
        return None, None, [], "Only PNG/JPG are supported.", ""

    # 1) ì—…ë¡œë“œ ë³´ê´€
    up_path = UPLOAD_DIR / in_path.name
    with open(in_path, "rb") as fsrc, open(up_path, "wb") as fdst:
        fdst.write(fsrc.read())

    # 2) Protect: ì›Œí„°ë§ˆí¬(UUID)
    payload = uuid.uuid4().hex
    wm_only_path = OUTPUT_DIR / f"{in_path.stem}_WM.png"
    embed_watermark(str(up_path), str(wm_only_path), payload)

    # 3) Disrupt: ë¹ ë¥¸ CLIP-PGD (í´ë°± ê°€ëŠ¥)
    wm_rgb = _imread_rgb(str(wm_only_path))
    pd_rgb = disrupt_once(wm_rgb, steps=int(steps), eps=float(eps), alpha=float(alpha))
    pd_path = OUTPUT_DIR / f"{in_path.stem}_PD.png"
    _imwrite_rgb(str(pd_path), pd_rgb)

    # 4) UUID í…ìŠ¤íŠ¸ ì €ì¥ (ì¦ë¹™)
    uuid_path = OUTPUT_DIR / f"{in_path.stem}_uuid.txt"
    uuid_path.write_text(payload, encoding="utf-8")

    # 5) ì‹œê°í™”
    orig_rgb = _imread_rgb(str(up_path))
    heat, fft_pd, overlay, note = make_diagnostics(orig_rgb, pd_rgb)

    return (
        str(pd_path),               # ê²°ê³¼ ì´ë¯¸ì§€ (Protect+Disrupt)
        str(uuid_path),             # UUID íŒŒì¼
        [heat, fft_pd, overlay],    # ê°¤ëŸ¬ë¦¬: Heatmap, FFT, Overlay
        ("(CLIP not found â†’ Protect only) " if not _CLIP_OK else "") + note,
        payload                     # í™”ë©´ì—ë„ UUID í‘œê¸°
    )

# ---------------------------
# Decode helper (ì¦ë¹™ í™•ì¸ìš©)
# ---------------------------
def do_decode(file) -> str:
    if not file:
        return "Choose an image."
    try:
        msg = decode_watermark(file.name if hasattr(file, "name") else str(file))
        return msg if msg else "(Empty result)"
    except Exception as e:
        return f"Decode failed: {e}"

# ---------------------------
# Gradio UI  (êµì²´ ì˜ì—­ ì‹œì‘)
# ---------------------------

KOREAN_FONT_CSS = """
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;600;700&display=swap');
* { font-family: 'Noto Sans KR', system-ui, -apple-system, Segoe UI, Roboto, 'Helvetica Neue', Arial, 'Apple SD Gothic Neo', 'Noto Sans KR', 'ë§‘ì€ ê³ ë”•', 'Malgun Gothic', sans-serif; }
:root { --brand-blue: #2563eb; } /* Tailwind blue-600 ë¹„ìŠ·í•œ í†¤ */
.gradio-container { color: #111827; } /* ì„¤ëª…(ë³¸ë¬¸) ê²€ì€ìƒ‰ ê³„ì—´ */
.footer { opacity: .9; }
"""

theme = Soft(primary_hue="blue", neutral_hue="slate")

with gr.Blocks(
    title="OpenMark â€” ë³´ì´ì§€ ì•ŠëŠ” ë³´í˜¸ + ë°©í•´ (ì›ìƒ·)",
    theme=theme,
    css=KOREAN_FONT_CSS,
) as demo:
    gr.Markdown(
        "## OpenMark â€” **Protect + Disrupt (ì›ìƒ·)**\n"
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ **ë³´ì´ì§€ ì•ŠëŠ” ì›Œí„°ë§ˆí¬(UUID)** ì™€ **í•™ìŠµ ë°©í•´(Disrupt)** ê°€  ì ìš©ëœ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆì–´ìš”.  \n"
        "ì•„ë˜ â€˜ê²°ê³¼ë³´ê¸°â€™ì—ì„œëŠ” ì»´í“¨í„°ê°€ í•™ìŠµì„ ìœ„í•´ ì¸ì‹í•˜ëŠ” ëª¨ìŠµ(ì”ì°¨ íˆíŠ¸ë§µ, **FFT** ìŠ¤í™íŠ¸ëŸ¼, ì˜¤ë²„ë ˆì´)ì„ ë³¼ ìˆ˜ ìˆì–´ìš”."
    )

    with gr.Row():
        # ì¢Œì¸¡: ì…ë ¥ + ì˜µì…˜
        with gr.Column(scale=2):
            in_file = gr.File(
                label="ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG/JPG)",
                file_count="single",
                file_types=["image"],
            )

            steps = gr.Slider(
                minimum=1, maximum=8, value=3, step=1,
                label="ë°©í•´ ê°•ë„ (ë‹¨ê³„)",
                info="ë¹ ë¥´ê²ŒëŠ” 1, ê°•í•˜ê²ŒëŠ” 4~6 ê¶Œì¥(ì‹œê°„ ì¦ê°€)"
            )

            with gr.Accordion("ê³ ê¸‰ ì„¤ì • (ì„ íƒ)", open=False):
                eps = gr.Slider(
                    1/255, 12/255, value=8/255, step=1/255,
                    label="ìµœëŒ€ ë³€í™”ëŸ‰ Îµ (Lâˆ)",
                    info="í”½ì…€ ë‹¹ í—ˆìš© ìµœëŒ€ ë³€í™”. ë„ˆë¬´ í¬ë©´ í’ˆì§ˆ ì €í•˜"
                )
                alpha = gr.Slider(
                    1/255, 6/255, value=3/255, step=1/255,
                    label="ìŠ¤í… í¬ê¸° Î±",
                    info="PGD ì—…ë°ì´íŠ¸ í¬ê¸° (ë³´í†µ Îµì˜ 1/3~1/4)"
                )

            btn_run = gr.Button("ì›ìƒ· ì ìš© (Protect + Disrupt)", variant="primary")

            gr.Markdown(
                """
                ğŸ’¡ **Tip**: ì´ˆê³ ì† ì²´í—˜ì€ ë‹¨ê³„(**steps**)ë¥¼ **1**ë¡œ ì„¤ì •í•´ ë³´ì„¸ìš”.  
                ë‹¨ê³„ê°€ ë†’ì„ìˆ˜ë¡ ë°©í•´íš¨ê³¼ëŠ” ê°•í•´ì§€ì§€ë§Œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.

                ### ğŸ“˜ ë„ì›€ë§ (ê°„ë‹¨ ì„¤ëª…)

                <span style="display:inline-block; background-color:#3b82f6; color:white; 
                             padding:4px 8px; border-radius:6px; font-weight:bold;">
                    UUID(ê³ ìœ ë²ˆí˜¸)
                </span><br>
                 ì‚¬ì§„ë§ˆë‹¤ ë¶™ëŠ” ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ê°™ì€ ê³ ìœ  ë²ˆí˜¸  
                 ë‚˜ì¤‘ì— 'ì´ ì‚¬ì§„ì€ ë‚´ ê±°ë‹¤!' í•˜ê³  ì¦ëª…í•  ìˆ˜ ìˆì–´ìš”.

                <span style="display:inline-block; background-color:#3b82f6; color:white; 
                             padding:4px 8px; border-radius:6px; font-weight:bold;">
                    Disrupt(ë°©í•´)
                </span><br>
                 ì»´í“¨í„°ê°€ ì‚¬ì§„ì„ ë°°ìš°ì§€ ëª»í•˜ê²Œ í—·ê°ˆë¦¬ê²Œ ë§Œë“œëŠ” ê¸°ìˆ   
                 ì‚¬ëŒ ëˆˆì—ëŠ” ê±°ì˜ ì•ˆ ë³´ì´ì§€ë§Œ, LLMì€ ì œëŒ€ë¡œ í•™ìŠµ ëª» í•˜ê²Œ ë¼ìš”.

                <span style="display:inline-block; background-color:#3b82f6; color:white; 
                             padding:4px 8px; border-radius:6px; font-weight:bold;">
                    Residual Heatmap(ì”ì°¨ íˆíŠ¸ë§µ)
                </span><br>
                  ë°ì„ìˆ˜ë¡ **ë” ë§ì´ ë°”ë€ í”½ì…€**<br>
                  ëˆˆìœ¼ë¡  ì˜ ì•ˆ ë³´ì´ëŠ” ë¯¸ì„¸ ë³€í™”ë¥¼ ìƒ‰ìœ¼ë¡œ ë³´ì—¬ì¤˜

                <span style="display:inline-block; background-color:#3b82f6; color:white; 
                             padding:4px 8px; border-radius:6px; font-weight:bold;">
                    FFT(ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼)
                </span><br>
                  ì´ë¯¸ì§€ì˜ **ìˆ¨ì€ íŒ¨í„´ X-ray**
                  ê°€ìš´ë°ê°€ ë°ìœ¼ë©´ ìì—°ìŠ¤ëŸ¬ìš´ í¸<br> ë§/ì¤„ë¬´ëŠ¬ê°€ ë³´ì´ë©´ **êµë€ í”ì **ì´ ë‚¨ì€ ê±°ì˜ˆìš”

                <span style="display:inline-block; background-color:#3b82f6; color:white; 
                             padding:4px 8px; border-radius:6px; font-weight:bold;">
                    Overlay
                </span><br>
                  ìµœì¢…ì ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ì´ ì¸ì‹í•˜ëŠ” ì´ë¯¸ì§€  
                """,
                elem_id="help-box"
            )
        # ìš°ì¸¡: ê²°ê³¼/UUID/ì§„ë‹¨/UUID í…ìŠ¤íŠ¸
        with gr.Column(scale=3):
            out_img = gr.Image(
                label="ê²°ê³¼ ì´ë¯¸ì§€ (ì›Œí„°ë§ˆí¬ + ë°©í•´)",
                interactive=False
            )

            with gr.Row():
                out_uuid = gr.File(label="UUID ë‹¤ìš´ë¡œë“œ (.txt)")
                uuid_text = gr.Textbox(
                    label="UUID (ê¸°ë¡ìš©)",
                    interactive=False,
                    placeholder="ìƒì„±ëœ UUIDê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."
                )

            gr.Markdown("#### ì§„ë‹¨ ë³´ê¸° â€” ëª¨ë¸ì´ â€˜ë³´ëŠ”â€™ í”ì  (ì˜µì…˜)")
            diag = gr.Gallery(
                label="Residual Heatmap / FFT / Overlay",
                columns=3,
                height=320,
                show_label=True
            )
            info = gr.Markdown("")  # PSNR ë“± ìˆ˜ì¹˜

    # ì‹¤í–‰ ì—°ê²°
    btn_run.click(
        fn=run_one_shot,
        inputs=[in_file, steps, eps, alpha],
        outputs=[out_img, out_uuid, diag, info, uuid_text],
    )

    gr.Markdown("---")
    gr.Markdown("### ë””ì½”ë“œ í™•ì¸ (ì„ íƒ) â€” ê²°ê³¼ ì´ë¯¸ì§€ì—ì„œ UUID ë³µì›í•´ë³´ê¸°")

    with gr.Row():
        dec_in = gr.File(
            label="OpenMark ë³´í˜¸ê°€ ì ìš©ëœ ì´ë¯¸ì§€ ì„ íƒ",
            file_count="single",
            file_types=["image"],
        )
        dec_btn = gr.Button("ë””ì½”ë“œ ì‹¤í–‰", variant="secondary")
        dec_out = gr.Textbox(label="ë³µì›ëœ UUID", interactive=False)

    dec_btn.click(fn=do_decode, inputs=[dec_in], outputs=[dec_out])



if __name__ == "__main__":
    demo.launch()